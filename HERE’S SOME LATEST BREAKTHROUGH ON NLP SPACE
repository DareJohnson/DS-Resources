BERT
https://lnkd.in/fR6p4Ut
Sequence Classification with Human Attention
https://lnkd.in/fen6xB8
Phrase-Based & Neural Unsupervised Machine Translation
https://lnkd.in/fE4CfVF
Probing sentence embeddings for linguistic properties
https://lnkd.in/fHpE3KP
SWAG
https://lnkd.in/fgPSxTG
Deep contextualized word representations
https://lnkd.in/ftMAz-g
Meta-Learning for Low-Resource Neural Machine Translation
https://lnkd.in/fYF5Hsx
Linguistically-Informed Self-Attention for Semantic Role Labeling
https://lnkd.in/fkz8usu
A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks
https://lnkd.in/fGYsEcD
Unanswerable Questions for SQuAD
https://lnkd.in/fddKepX
An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling
https://lnkd.in/fa6a8FJ
Universal Language Model Fine-tuning for Text Classification
https://lnkd.in/fnTzYpw
Improving Language Understanding by Generative Pre-Training
https://lnkd.in/fpA73wA
Dissecting Contextual Word Embeddings: Architecture and Representation
https://lnkd.in/fg6ck7w

Original by TOPBOTS https://lnkd.in/f_8R-8e
